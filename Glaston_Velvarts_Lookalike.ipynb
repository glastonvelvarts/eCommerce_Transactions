{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glaston_Velvarts_Lookalike.csv file generated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load datasets\n",
    "customers = pd.read_csv('Customers.csv')\n",
    "products = pd.read_csv('Products.csv')\n",
    "transactions = pd.read_csv('Transactions.csv')\n",
    "\n",
    "# Merge datasets to create a full dataset\n",
    "transactions_customers = transactions.merge(customers, on=\"CustomerID\", how=\"inner\")\n",
    "full_data = transactions_customers.merge(products, on=\"ProductID\", how=\"inner\")\n",
    "\n",
    "# Step 1: Aggregate customer-level data\n",
    "customer_profiles = full_data.groupby(\"CustomerID\").agg({\n",
    "    \"TotalValue\": [\"sum\", \"mean\"],  # Total and average spend\n",
    "    \"Quantity\": \"sum\",             # Total quantity purchased\n",
    "    \"Category\": lambda x: list(x.unique()),  # Unique categories purchased\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten multi-level columns\n",
    "customer_profiles.columns = [\"CustomerID\", \"TotalSpend\", \"AvgSpend\", \"TotalQuantity\", \"Categories\"]\n",
    "\n",
    "# Step 2: One-hot encode the categories\n",
    "categories = pd.get_dummies(full_data[[\"CustomerID\", \"Category\"]], columns=[\"Category\"]).groupby(\"CustomerID\").sum()\n",
    "\n",
    "# Step 3: Combine customer features with one-hot encoded categories\n",
    "customer_features = customer_profiles.merge(categories, on=\"CustomerID\")\n",
    "customer_features = customer_features.drop(columns=[\"Categories\"])  # Drop non-numeric \"Categories\" column\n",
    "\n",
    "# Step 4: Normalize numerical data\n",
    "scaler = StandardScaler()\n",
    "customer_features.iloc[:, 1:] = scaler.fit_transform(customer_features.iloc[:, 1:])\n",
    "\n",
    "# Step 5: Compute cosine similarity\n",
    "similarity_matrix = cosine_similarity(customer_features.iloc[:, 1:])\n",
    "similarity_df = pd.DataFrame(\n",
    "    similarity_matrix,\n",
    "    index=customer_features[\"CustomerID\"],\n",
    "    columns=customer_features[\"CustomerID\"]\n",
    ")\n",
    "\n",
    "# Step 6: Generate top 3 lookalikes for the first 20 customers\n",
    "lookalikes = {}\n",
    "\n",
    "for customer_id in similarity_df.index[:20]:  # Limit to the first 20 customers\n",
    "    # Sort similarity scores in descending order, exclude the customer itself\n",
    "    similar_customers = similarity_df.loc[customer_id].sort_values(ascending=False).iloc[1:4]\n",
    "    lookalikes[customer_id] = list(zip(similar_customers.index, similar_customers.values))\n",
    "\n",
    "# Step 7: Convert lookalike results to the required format for CSV\n",
    "lookalike_list = []\n",
    "\n",
    "for customer_id, similar_customers in lookalikes.items():\n",
    "    lookalike_list.append({\n",
    "        \"cust_id\": customer_id,\n",
    "        \"similar_customers\": similar_customers\n",
    "    })\n",
    "\n",
    "# Step 8: Create a DataFrame and save to CSV\n",
    "lookalike_df = pd.DataFrame(lookalike_list)\n",
    "lookalike_df[\"similar_customers\"] = lookalike_df[\"similar_customers\"].apply(lambda x: [f\"({c}, {s:.4f})\" for c, s in x])\n",
    "lookalike_df.to_csv(\"Glaston_Velvarts_Lookalike.csv\", index=False)\n",
    "\n",
    "print(\"Glaston_Velvarts_Lookalike.csv file generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
